{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    通过学习NLP，找到好工作\n",
    "    2.2. what problems do you want to solve？\n",
    "    首先是工作，其次是想掌握人工智能这门技术\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    有一定的编程基础，主要是C++方面\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    NLP接触不多，语言学基础方面比较薄弱，有待提高\n",
    "    2.5. How will you plan to study in this course period?\n",
    "    多学，多练，多思考\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {翻译，语音识别，自动驾驶，对话机器人}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {GIthub是一个分布式的文件系统，可以上传文档，包括代码，文件等，与他人共享；Jupyter用于编写代码，并且可以运行，并显示结果；Pycharm是一个python的IDE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:概率模型是用来描述不同随机变量之间关系的数学模型，通常情况下刻画了一个或多个随机变量之间的相互非确定性的概率关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:打麻将时的掷骰子决定摸牌顺序；根据往年的天气情况，预测某一天下雨的可能性（奥运会就预测过）；统计海洋的渔业资源；统计广东的蚊子数量等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:某些事件不具有确定性的数学关系，采用统计的方法来度量这些事件，这时就需要概率模型。模式匹配的难点在于模式的多样性和多变性，无法用有限的模式，来描述事件的所有情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型是根据语言客观事实而进行的语言抽象数学建模，是一种对应关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:翻译，语音识别，英语考试中的改错题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:单个词语在一段语言序列的概率分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:优点是便于统计，缺点是缺乏上下文语境的理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:两个词语在一定情况下同时出现的概率分布模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hobby = '''\n",
    "hobby = name* state* thing*\n",
    "name* = name | name name*\n",
    "name = 你 | 我 | 他 | 小明 | 你们 | 我们 | 他们\n",
    "state* = state | state state*\n",
    "state = 喜欢 | 讨厌  \n",
    "thing* = thing | thing thing*\n",
    "thing = 篮球 | 足球 | 游泳 | 读书 | 打架 | 斗殴\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here\n",
    "#论文写作结构分析\n",
    "paper = '''\n",
    "paper =  问题式 | 什么式 | 假设式\n",
    "问题式 = 提出问题*  --> 分析问题* -->  解决问题*  \n",
    "提出问题* = 提出问题 | 提出问题 提出问题*\n",
    "提出问题 = 问题 编号* ？\n",
    "分析问题* = 分析问题 | 分析问题 分析问题*\n",
    "分析问题 = 分析 编号* 。 \n",
    "解决问题* = 解决问题 | 解决问题 解决问题*\n",
    "解决问题 = 解决方法 编号* 。\n",
    "编号* = 编号 | 编号 编号*\n",
    "编号 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9\n",
    "什么式 = 是什么* --> 为什么* --> 怎么办* \n",
    "是什么* = 是什么 | 是什么 是什么*\n",
    "是什么 = 编号* 是 编号*  。 \n",
    "为什么* =  为什么 | 为什么 为什么*\n",
    "为什么 =  因为 因由 。| 由于 因由 。\n",
    "因由 = 原因 编号* \n",
    "怎么办* =  怎么办 | 怎么办 怎么办*\n",
    "怎么办 =  解决办法 编号* 。 \n",
    "假设式 = 提出假设* --> 验证* --> 结论*\n",
    "提出假设* = 提出假设 | 提出假设 提出假设*\n",
    "提出假设 = 假设 编号* 存在 。\n",
    "验证* =  验证 | 验证 验证* \n",
    "验证 =  证据 编号* 。 | 实验 编号* 。\n",
    "结论* = 结论 | 结论 结论*\n",
    "结论 = 证明假设 编号 是 判断 。\n",
    "判断 = 对的 | 确的 | 错的 |  错误的 | 不对的  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGramma(gramStr,lineSplit='\\n',wordSplit='|',keyValueSplit='='):\n",
    "    gram = {}\n",
    "    for line in gramStr.split(lineSplit):\n",
    "        if not line.strip(): continue\n",
    "        #print(line)\n",
    "        key,values = line.split(keyValueSplit)\n",
    "        gram[key.strip()] = [v.split() for v in values.split(wordSplit)]\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice\n",
    "def createSentence(rule,gram):       \n",
    "    if gram not in rule: return gram\n",
    "    s = [createSentence(rule,v) for v in choice(rule[gram])]\n",
    "    return ''.join(t for t in s)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3是4。51是512。-->由于原因1133。由于原因83。-->解决办法8。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createSentence(createGramma(paper),'paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你们喜欢读书'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createSentence(createGramma(hobby),'hobby')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(rule,gram,number):\n",
    "    sen = []\n",
    "    for i in range(number):\n",
    "        sen.append(createSentence(createGramma(rule),gram))\n",
    "    return sen      \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 - paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['假设287存在。假设25存在。-->实验7。证据8。实验26。证据9。-->证明假设8是不对的。',\n",
       " '4是7629。43是4。9是143。51是99。-->因为原因98。因为原因3。因为原因4。-->解决办法95318。解决办法92。',\n",
       " '问题94？问题4？问题8？-->分析9。分析5。-->解决方法8。解决方法3。',\n",
       " '问题175？问题72？问题4？-->分析7。分析8。-->解决方法7。解决方法6622625。解决方法3。解决方法414。',\n",
       " '31是8。-->因为原因4。由于原因862。因为原因18357575986。-->解决办法16652。',\n",
       " '假设7存在。假设5存在。假设3存在。假设14存在。假设7存在。-->证据66885。证据4。-->证明假设9是错的。证明假设8是确的。证明假设9是对的。证明假设6是错误的。证明假设4是错误的。',\n",
       " '431是92。-->因为原因1。由于原因2。-->解决办法38。解决办法7。',\n",
       " '假设3存在。-->实验14。-->证明假设4是确的。证明假设6是错的。',\n",
       " '问题13？-->分析679。分析7。-->解决方法842。解决方法5。解决方法8。',\n",
       " '假设1存在。假设55存在。-->证据8。实验73。实验1296。-->证明假设8是确的。证明假设2是错误的。证明假设6是不对的。证明假设2是不对的。证明假设8是对的。证明假设9是错误的。证明假设3是错的。',\n",
       " '假设2存在。-->证据2581。-->证明假设9是确的。证明假设3是对的。证明假设1是确的。证明假设6是不对的。证明假设9是不对的。证明假设9是错误的。证明假设8是对的。',\n",
       " '假设746存在。-->证据3。证据6。证据76。-->证明假设5是对的。证明假设7是不对的。证明假设3是错的。证明假设5是错的。',\n",
       " '5是5。-->由于原因3。-->解决办法2849。',\n",
       " '问题8？问题3？-->分析2。分析9。-->解决方法246。解决方法9。解决方法5。',\n",
       " '假设4存在。假设4存在。假设47353存在。-->证据365762。-->证明假设9是对的。',\n",
       " '假设7存在。-->实验85。实验85。-->证明假设6是不对的。证明假设7是确的。',\n",
       " '2565是729。-->由于原因32。-->解决办法5。解决办法9。',\n",
       " '问题32？-->分析9996。分析2。-->解决方法6。解决方法7。',\n",
       " '假设5存在。-->证据9。实验448。证据7。-->证明假设2是错的。证明假设5是确的。证明假设8是错误的。',\n",
       " '问题6？-->分析616。分析37。-->解决方法478。']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(paper,'paper',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 - hobby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['你喜欢篮球',\n",
       " '他小明他们讨厌足球打架',\n",
       " '他们喜欢喜欢读书',\n",
       " '小明喜欢讨厌讨厌游泳',\n",
       " '他我们你讨厌讨厌喜欢讨厌打架',\n",
       " '我喜欢讨厌喜欢喜欢打架读书篮球斗殴',\n",
       " '他们我们我们你们我们我们我喜欢讨厌喜欢打架斗殴',\n",
       " '小明讨厌讨厌足球游泳',\n",
       " '我喜欢讨厌游泳游泳',\n",
       " '我讨厌讨厌斗殴斗殴斗殴斗殴',\n",
       " '他喜欢篮球',\n",
       " '小明我你们小明你讨厌讨厌读书',\n",
       " '你们讨厌喜欢斗殴斗殴',\n",
       " '你们讨厌讨厌喜欢游泳',\n",
       " '你他们讨厌打架游泳游泳',\n",
       " '小明喜欢讨厌篮球',\n",
       " '你们他们小明他们你讨厌讨厌打架斗殴',\n",
       " '你们讨厌打架足球',\n",
       " '他们他们喜欢讨厌喜欢讨厌斗殴',\n",
       " '他们我们讨厌打架']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(hobby,'hobby',20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本清洗："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanText(sourceFileName,targetFileName=''):\n",
    "    sourText = open(sourceFileName,'r',encoding='utf8').read()\n",
    "    #target = re.findall(r'[\\u4e00-\\u9fa5]',sourText)\n",
    "    target = re.findall('\\w+',sourText)\n",
    "    if targetFileName: \n",
    "        targetFile = open(targetFileName,'w',encoding='utf8')\n",
    "        for text in target:\n",
    "            #print(text)\n",
    "            targetFile.write(text)\n",
    "        targetFile.close()\n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集1加载与清洗"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sourceFileName = 'D:\\python\\datasource\\train.txt'\n",
    "targetFileName = \"D:\\python\\datasource\\cleanTrain.txt\"\n",
    "\n",
    "text = cleanText(sourceFileName,targetFileName)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### 加载数据集2，处理并保存\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sourceFile = 'D:\\python\\datasource\\movie_comments.csv'\n",
    "content = pd.read_csv(sourceFile,encoding='utf8')\n",
    "articles = content['comment'].tolist()\n",
    "articlesText = [str(a) for a in articles]\n",
    "with open('D:\\python\\datasource\\movie_comments.txt', 'w',encoding='utf8') as f:\n",
    "    for a in articlesText:\n",
    "        f.write(a + '\\n')\n",
    "del articlesText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集2清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFileName = 'D:\\python\\datasource\\movie_comments.txt'\n",
    "targetFileName = \"D:\\python\\datasource\\cleanMovieComments.txt\"\n",
    "\n",
    "text = cleanText(sourceFileName,targetFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "983702"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吴京意淫到了脑残的地步', '看了恶心想吐', '首映礼看的', '太恐怖了这个电影', '不讲道理的', '完全就是吴京在实现他这个小粉红的英雄梦', '各种装备轮番上场', '视物理逻辑于不顾', '不得不说有钱真好', '随意胡闹', '吴京的炒作水平不输冯小刚', '但小刚至少不会用主旋律来炒作', '吴京让人看了不舒服', '为了主旋律而主旋律', '为了煽情而煽情', '让人觉得他是个大做作', '大谎言家', '7', '29更新', '片子整体不如湄公河行动', '1', '整体不够流畅', '编剧有毒', '台词尴尬', '2', '刻意做作的主旋律煽情显得如此不合时宜而又多余', '凭良心说', '好看到不像', '战狼1', '的续集', '完虐', '湄公河行动', '中二得很', '犯我中华者', '虽远必诛', '吴京比这句话还要意淫一百倍', '脑子是个好东西', '希望编剧们都能有', '三星半', '实打实的7分', '第一集在爱国主旋律内部做着各种置换与较劲', '但第二集才真正显露吴京的野心', '他终于抛弃李忠志了', '新增外来班底让硬件实力有机会和国际接轨', '开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶', '在理念上', '它甚至做到', '绣春刀2', '最想做到的那部分', '开篇长镜头惊险大气引人入胜', '结合了水平不俗的快剪下实打实的真刀真枪', '让人不禁热血沸腾', '特别弹簧床架挡炸弹', '空手接碎玻璃', '弹匣割喉等帅得飞起', '就算前半段铺垫节奏散漫主角光环开太大等也不怕', '作为一个中国人', '两个小时弥漫着中国强大得不可侵犯的氛围', '还是让那颗民族自豪心砰砰砰跳个不停', '15', '100吴京的冷峰在这部里即像成龙', '又像杰森斯坦森', '但体制外的同类型电影', '主角总是代表个人', '无能的政府需要求助于这些英雄才能解决难题', '体现的是个人的价值', '所以主旋律照抄这种模式实际上是有问题的', '我们以前嘲笑个人英雄主义', '却没想到捆绑爱国主义的全能战士更加难以下咽', '犯我中华者虽远必诛', '是有多无脑才信这句话', '这部戏让人看的热血沸腾', '对吴京路转粉', '最后的彩蛋', '让我们没有理由不期待下一部', '假嗨', '特别恶心的电影', '有几处情节设置过于尴尬', '彰显国家自豪感的部分稍显突兀', '就是一部爽片', '打戏挺燃', '但是故事一般', '达康书记不合适这个角色', '赵东来倒是很合适', '张瀚太太太违和了', '分分钟穿越回偶像剧', '赵东来', '达康书记', '我们接到在非洲卧底的冷锋报告', '丁义珍现在非洲', '我们请求抓捕', '李达康', '东来', '这件事先不要声张', '特别是别让省厅知道', '就你和我一起去非洲', '加上冷锋同志', '三人逮捕丁义珍', '这次行就叫战狼2吧', '下一部拍喜剧吧', '整个片子真感觉挺搞笑的', '战狼2', '里吴京这么能打', '他打得过徐晓冬么', '心往一处想', '劲往一处使', '就能实现我们的梦想', '看吧', '比第一部好太多了', '谢谢美队的动作指导', '这都能火', '是我没见识', '开头的水下长对决戏可算华语电影的顶尖存在', '驱逐舰', '导弹和坦克在商业片里这么狂用也是了得', '镜头运用和笑点插入都很好莱坞爆米花', '不功不过', '从头打到尾是真拼', '虽然镜头也有略乱时', '因为没啥期望值', '所以被吴京的野心吓了一跳', '吴刚', '于谦和丁海峰老三位像炖烂熟的牛筋', '嚼着就舒服', '很用心啊吴京导演', '小看你了', '确实在导演上下功夫了拉片子了', '知道借鉴是好的', '至于大家比较反感的小粉红情绪我觉得那些桥段都是主旋律必备啊是稍微有一点过但还可以接受', '最好的地方是吴京节奏掌握得很好', '知道张弛有度', '这点很难得', '犯我中华者虽远必诛', '这句话一直在我脑子里回响', '片头海里那场动作戏看完就呆不下去了', '太假太做作', '提前离场', '好看', '这部戏让人看的热血沸腾', '打戏挺燃的', '吴京演技棒呆了', '符合', '有钱了续集反而拍更差', '这一放之四海而皆准的规律', '场面越做越大', '然而伴随着各种动作场面和特效场面的升级', '这一部的叙事反而变得非常凌乱', '格局颇大', '想拍成', '黑鹰坠落', '结果撑死最多也只是官方主旋律版的', '敢死队', '吴京确实有野心', '但论自我角色定位能力远不如同是动作演员出身的甄子丹', '说喜欢这部片子的人不是装傻就是真傻', '要不是真的没有别的可看肯定是不会选这部的', '直男癌到令人发指', '所有剧情走向也完全是九十年代那套照搬', '审美这件事儿真不是一时半会儿能培养出来的', '整部电影延续1的风格', '热血', '场面比1来的要大', '打戏动作不错', '吴京挺适合演军人的', '电影之前的中国梦片段他都念的劲儿劲儿的', '整体来说还不错', '不过张翰太违和了', '一出来就一股雷阵雨的画风', '目瞪狗呆', '太瘠薄好看了', '中国人牛b就是硬道理', '隔壁建军大爷都没你们爱国', '战狼2', '的动作场景和战斗装备全线升级', '热血的打斗动作从头打到尾', '战狼2', '游走在电影审查红线的边界和政治安全的缝隙', '是部延续了第一部极具煽动爱国情绪的国产动作大片', '如此制作精良的影片', '还请多来一点', '电影用的胶卷挺差的', '故事过度也差', '地方部队还没太多展示就死去', '反正各种问题', '但就是能吸引人看下去', '就冲这', '为什么要这么鄙视敢想敢去开拓的人', '不允许他们再去拍', '直到能有更好的人', '拍出更棒的更出彩的电影来呢', '火爆的场面拍出了好莱坞大片的感觉', '本片必将燃爆暑期', '吴京厉害了', '身为武打演员', '能拍到这么高标准的大场面的枪战戏', '为你点赞', '热血男儿', '荷尔蒙爆发', '能给0星么', '好恶心啊', '血战钢锯岭', '中国人也会觉得好看', '因为它歌颂的宗教情怀是超越政权的', '但当你只想歌颂一个政权时', '很明显就低了一个层次', '甚至充满了现实乃至投机的考量', '高下立见', '请问吴京脑残', '弹簧床能挡火箭炮吗', '上一部是傲气雄鹰', '这一部是第一滴血4', '吴京算是国内导演对类型片感觉比较准的', '作为动作片钱都花在有效地方', '整体火爆流畅', '有大片气魄', '创作上也足够真诚', '人物设计也都不错', '连张翰都很可爱了', '如果吴京不像当年甄子丹那样一时膨胀', '在银幕上独占聚光灯', '肯定可以走得更远', '扪心自问这种电影真没法评价', '全片靠动作戏撑完', '文戏都是扯淡', '女主角毫无存在的必要', '故事不需要逻辑只要主角开挂', '但牛逼之处在于全片都透露着极强烈的爱国主义光环和意识形态枷锁', '在祖国面前', '一切反动派都是纸老虎', '所以战狼一个人开挂团灭一个连都是合情合理的', '动作戏还不错', '挺用心', '两星鼓励', '扪心自问这种电影真没法评价', '全片靠动作戏撑完', '文戏都是扯淡', '女主角毫无存在的必要', '故事不需要逻辑只要主角开挂', '但牛逼之处在于全片都透露着极强烈的爱国主义光环和意识形态枷锁', '在祖国面前', '一切反动派都是纸老虎', '所以战狼一个人开挂团灭一个连都是合情合理的', '动作戏还不错', '挺用心', '两星鼓励', '两星给打戏', '其他一般般', '没啥看点', '还有点尴尬', '太尴尬了', '手接炸弹', '哈哈哈', '从张翰出来之后', '我就想炸了他', '翻了一下我给第一部的评价是四星', '当时觉得挺燃的', '这部其实在完成度上更接近好莱坞的制作了', '每个步骤每个人物的走向都很顺滑', '没有任何出人意料的地方', '只给三星是因为', '看看最近现实世界的一切', '抱歉我在影院里燃不起来', '只是觉得一切都很魔幻', '当然开头的强拆是最有现实感的一幕了', '太喜欢', '战狼2', '开场6分钟长镜头的水下搏斗戏了', '从来没有在其它任何一部电影里看到过', '因为拍摄难度真的不一般', '同时还对演员有各种技能方面的要求', '看完片子回来搜了下', '被吴京会游泳', '潜水', '滑雪', '开飞机', '开坦克', '射击等各项技能', '还特意去特种部队当过18个月兵', '真的很佩服这样的电影人', '3星半', '1', '电影结束有掌声出现', '近期少见', '2', '一粒爱国主义大补丸', '有人吃的开心', '有人觉得补大了', '3', '从头打到尾', '从白打到黑', '4', '从片头字幕到影片细节', '完全展现了吴京作为一个超级直男的糙和猛', '主角光环媲美终结者', '5', '达康书记无亮点', '张翰变谐星', '6', '3D', '7', '导演的掌控能力逼近Hold不住的边缘', '打戏非常带感', '燃爆了', '拳拳到肉', '看得超爽', '吴京确实很聪明', '很鸡贼', '在一面大旗下呈现了一出重工业娱乐电影', '他一直调控着说教和娱乐的比例', '娱乐多了', '尺度不被允许', '说教多了', '大众不接纳', '比例把握非常微妙', '这其中还是有一些', '奇侠', '化的内容', '比如用玻璃碴子当飞镖杀敌一类', '只不过被遮盖掉了', '老爹', '演过美剧', '搏击王国', '力荐那部美剧', '作为主旋律影片为啥用', '奇异恩典', '配乐', '画内镜头还是中国军人', '男生看这部电影的话', '应该会很喜欢', '因为很刺激肾上腺素', '如果是女生', '冷锋对龙小云的感情也会十分打动你', '真的', '无脑动作片', '模仿许多好莱坞大场面再想怎么玩怎么玩一股脑堆', '槽点多到炸', '几位主角血厚到科幻级别', '吴京重复演满血', '红血', '中毒', '极速回血', '爆种打通全场', '确实很拼但片子太过投机取巧', '炸穿银幕连迈克尔贝都不受待见了', '国片还前仆后继炸不停', '故事不好看堆再多大场面大爆炸假high瞎燃也没用', '5', '10', '吴京', '这种女人就缺我这样的男人征服', '心往一处想', '劲往一处使', '就能实现吴京直男癌的中国梦', '美国大片就能意淫', '国产的就不行', '美国的就打不死', '全都跳飞机跟跳墙一样', '中国就不行', '好莱坞总是美国总是拯救世界', '国产片就是中国梦想拯救非洲', '以现在的中印局势', '来对比这部电影假想的内容', '还真是挺讽刺的哈哈哈', '谄媚投机到恶心', '作为军旅题材给四星我觉得不过分', '质感燃到爆炸', '燃', '大场面真的不输国外大片不尴尬', '吴京打戏很精彩', '水下搏斗看着也很有力', '必须安利一下张翰', '这角色简直就是个彩蛋啊', '承包所有笑点', '为他量身定做的哈哈哈', '彭于晏可演不来', '是真的好看', '战狼2', '的制作明显比第一部升级了不少', '坦克漂移', '无人机突袭', '直升机坠露', '水下肉搏', '军舰导弹发射', '场面和动作再加上非洲叛乱国际化的视角完全是好莱坞大片的标配', '吴京饰演的冷锋更加深入人心', '如此搏命的精神在当下华语动作电影算是少见了', '期待第三部', '好燃啊', '好看', '表白吴京和达康书记', '燃', '大场面真的不输国外大片不尴尬', '吴京打戏很精彩', '水下搏斗看着也很有力', '必须安利一下张翰', '这角色简直就是个彩蛋啊', '承包所有笑点', '为他量身定做的哈哈哈', '彭于晏可演不来', '是真的好看', '战狼2', '的制作明显比第一部升级了不少', '坦克漂移', '无人机突袭', '直升机坠露', '水下肉搏', '军舰导弹发射', '场面和动作再加上非洲叛乱国际化的视角完全是好莱坞大片的标配', '吴京饰演的冷锋更加深入人心', '如此搏命的精神在当下华语动作电影算是少见了', '期待第三部', '好燃啊', '好看', '表白吴京和达康书记', '典型美国大片的方式', '每次都能猜对剧情', '没劲诶', '我就想问', '王牌特工就那么点杀人的镜头', '还经过艺术处理', '都直接删了', '战狼2这种血腥屠杀的镜头', '赤裸裸的', '大段大段的', '是怎么过的', '政治正确就有庇衣了', '意料之中的精彩', '意料之外的惊喜', '属于我们的英雄', '展现狼性的军魂', '几个网红拉出来弹弹琴你们就说燃了', '彰显我大国气象荷尔蒙满屏', '这TM才叫燃', '这部电影告诉我们中国人也是可以拯救世界的', '吴迪塞尔如入无人之境', '7亿大陆直男在这一刻集体勃起', '心往一处想', '劲往一处使', '你就能离开影厅不是个屌丝了', '同样是主旋律', '片子比电影开始前的', '我的中国梦', '要屌一万倍', '吴京这一次完全就是用超级英雄的标准来打造角色', '美式英雄主义与主旋律的违和是不可逆转的缺点', '各种笑料也一定程度地破坏了节奏感', '斥巨资炮制的大场面有所体验', '动作场面的流畅自然也比得上好莱坞水准', '但满到溢出却又影响了观感', '有着明显的优缺点', '但却会是受一般观众喜爱的院线电影', '两星半', '3d扣分', '和第一部同样精彩', '看完之后我热血澎拜啊', '纯粹拍的很难看啊', '集体癔症', '这个系列从1开始就跟吃了壮阳药似的', '张翰脸比女主白太多了', '请问用了什么护肤品', '客观的说七分', '虽然情节逻辑有各种经不起推敲的细节', '但总体完成度很高', '虽然反派有点无脑脸谱化', '但配角形象还算丰满', '尤其张瀚的富二代形象居然不招人讨厌', '有笑点有泪点', '是部用心的片子', '瑕不掩瑜', '值得鼓励', '在吴京的个人英雄幻想下连主旋律都沦为附庸了', '我tm还能说什么', '主角已经牛逼到突破逻辑的地步', '全天下超级无敌牛逼就是你了好啦好啦我都知道', '1', '看看人家装逼装得多专业', '2', '由于全国发布高温警报', '主角只好去非洲避暑了', '3', 'Tundu', '我不要去中国', '中国太他妈热了', '我会被晒黑的', '4', '张翰在本片饰演亦凡', '整个太平洋都是他承包的鱼塘', '5', '达康书记', '东来局长都是幌子', '实际上反派是美队对冷锋的考验', '下集他将加入复联一起打灭霸', '三星半', '与首部一脉相承', '但脱离了军旅题材的限制', '变成了孤胆英雄动作片', '与第一滴血系列是一样的', '故事不新鲜', '但场面更大', '动作部分在技巧', '火爆之间切换', '整体非常燃', '片长有些长', '能看出拍摄时受限颇多', '有的镜头一看就是硬性指标', '但这样的片对拓展华语类型片有好处', '还是多多益善', '已三刷', '不明白为什么会有人说中二和吴京意淫', '这种类型的电影肯定要有一个英雄人物带动情节的发展', '真的好看', '全场无尿点', '谁会希望有战乱', '一些人或群体为了自己的私人利益', '发动战争', '但这苦的可是手无寸铁之力的民众', '祈求一个永远也实现不了的愿望', '世界和平', '黑子跪久了都站不起来了', '5分力荐', '张翰脸比女主白太多了', '请问用了什么护肤品', '客观的说七分', '虽然情节逻辑有各种经不起推敲的细节', '但总体完成度很高', '虽然反派有点无脑脸谱化', '但配角形象还算丰满', '尤其张瀚的富二代形象居然不招人讨厌', '有笑点有泪点', '是部用心的片子', '瑕不掩瑜', '值得鼓励', '在吴京的个人英雄幻想下连主旋律都沦为附庸了', '我tm还能说什么', '主角已经牛逼到突破逻辑的地步', '全天下超级无敌牛逼就是你了好啦好啦我都知道', '1', '看看人家装逼装得多专业', '2', '由于全国发布高温警报', '主角只好去非洲避暑了', '3', 'Tundu', '我不要去中国', '中国太他妈热了', '我会被晒黑的', '4', '张翰在本片饰演亦凡', '整个太平洋都是他承包的鱼塘', '5', '达康书记', '东来局长都是幌子', '实际上反派是美队对冷锋的考验', '下集他将加入复联一起打灭霸', '三星半', '与首部一脉相承', '但脱离了军旅题材的限制', '变成了孤胆英雄动作片', '与第一滴血系列是一样的', '故事不新鲜', '但场面更大', '动作部分在技巧', '火爆之间切换', '整体非常燃', '片长有些长', '能看出拍摄时受限颇多', '有的镜头一看就是硬性指标', '但这样的片对拓展华语类型片有好处', '还是多多益善', '已三刷', '不明白为什么会有人说中二和吴京意淫', '这种类型的电影肯定要有一个英雄人物带动情节的发展', '真的好看', '全场无尿点', '谁会希望有战乱', '一些人或群体为了自己的私人利益', '发动战争', '但这苦的可是手无寸铁之力的民众', '祈求一个永远也实现不了的愿望', '世界和平', '黑子跪久了都站不起来了', '5分力荐', '样板戏走向全球', '捧高美国队长', '贬低战狼', '双重标准不要玩的太溜', '好莱坞玩爱美国就是高大上', '国内玩爱国就是假大空', '真不懂你们这些没有膝盖的人', '二十年前', '当我还是个懵懂的小孩子', '看到这样的故事和镜头', '我会被感动的哭鼻子', '如今', '二十年过去了', '你却还拿这样的故事逻辑和镜头给我看', '我只能尴尬的笑', '战狼2', '可以说用军舰坦克', '撞开了国产电影重工业的大门', '让观众了解到国产电影也可以像好莱坞大片一样', '可以有自己的超级英雄', '说剧情有bug', '我承认', '但你看的燃不燃', 'high不high', '动作打得过瘾不过瘾', '看得心潮澎湃没有', '激动不', '国产商业动作片能拍到这个水准', '已经值得表扬了', '不给鼓励还在那挑刺', '呵呵', '这一星给开场拆房子的那场戏', '太不符合社会主义核心价值观了', '电影院', '一个人就买了四张票', '不打折', '请全家看', '心疼我的小钱钱', '还好家长们的反应是好的', '把吴京猛夸了一通', '中国式的动作大片并不逊色好莱坞', '只要他们满意我也就心满意足了', '我珍惜一家人和和气气的团聚时刻', '卢靖姗真漂亮', '干练明朗的健康美', '吴京好好拍', '第三部继续约啊', '听说过夜郎自大吗', '我第一次知道中国人这么牛逼', '中国部队所向披靡', '连特么坦克都能给你开漂移', '整部电影都是吴京一个人在意淫', '意淫真可怕', '中国维和单凭一个视频能越过联合国长驱直入到别国领土进行作战', '你当Africa是你家后院么', '意淫强国', '我身为天朝子民相当之荣幸', '扬我国威', '震我中华', '我跟你们讲', '吴京当年在电视上大吹牛逼', '说自己在杀破狼里和甄子丹真打', '多厉害多牛逼', '结果花絮里明明白白地展现了甄如何设计全套动作', '从头到尾手把手地教吴京', '中國狼不咬中國人', 'www', '冷锋像是一个符号', '他代表着千千万万守护我们的军人', '国强则民安', '生活在这个没有战争的国度', '我们真的算是非常幸福', '每一个军人都值得我们尊敬', '这个强大的祖国也值得我们热爱', '如同影片的主旨', '中国护照不能带你去任何一个国家', '但能从任何一个地方把你平安带回家', '非常难看', '也不知道导演哪儿来的自信', '一部政治宣传片', '中国也就在非洲还有点脸面了', '给宏大的战争场面和吴京卖力的打斗五星', '剧情减一星', '政治倾向剪一星', '综合三星', '诚意满满', '全程无尿点', '吴京非常帅', '剧情比战狼1好看多了', '23点45分开始', '1点48分结束', '我看了12次手机', '影厅的天花板上有8条线组合成三角形装饰', '18个音响在棚顶前12个并列排放', '后面6个33一组', '一共24个探照灯', '第12个旁边有个摄像头', '另外', '中国护照上没有那句话', '有一场坦克戏', '简直令人浮想连连啊', '吴京真的不是故意的嘛', '又是压人压成肉泥的镜头', '又是吴京站在坦克正前面', '稍有常识的人都会看出', '如果敌方的铁骑继续前进', '然而吴京这个螳臂当车的歹徒真的阻挡住了', 'wtf', '我为啥要看这个', '暴发户的自尊来源于深不见底的自卑', '无脑意淫片如此走红', '果然是钱多人傻', '战狼2', '里塑造了一个更加的真实与接地气', '有血有肉的英雄', '他让观众看到无限的可能', '让我们见到的是这个时代的英雄', '英雄在做的是人性的挣扎与人道的选择', '在向所有自以为是的正确选择做抗争', '这个时代恰恰缺少的是这样的英雄', '我用余光观察了下周围一起观影的人', '一群人一起翻白眼儿', '何其壮观', '好看', '是吴京的忠实影迷', '第一部就看的我热血沸腾', '第二部依旧如此', '看完感觉我的爱国魂在熊熊燃烧', '跟第一部比确实是不知道高到哪里去了', '本质上还是学资本主义毛皮', '吹社会主义牛逼', '连彩蛋都如此', '2', '5', '动作戏的场面拍的还算用心', '但逻辑怪力乱神', '至于剧情', '吴京他老人家开心就好', '打打打', '杀杀杀', '中国护照走天下', '政治正确的影片', '肯定过及格线', '虽远必诛', '除了印度', '没看过', '我找骂', '有人会来骂我吗', '很燃', '战争的场面很宏伟', '人与人的打斗很精彩', '看得人热血沸腾', '为同胞而战', '赵东来', '达康书记', '我们接到在非洲卧底的冷锋报告', '丁义珍现在非洲', '我们请求抓捕', '李达康', '东来', '这件事先不要声张', '特别是别让省厅知道', '就你和我一起去非洲', '加上冷锋同志', '三人逮捕丁义珍', '这次行就叫战狼2吧', '如果把爱国和评价主旋律电影捆绑在一起', '那对电影本身的尊重何在', '夸张的人设', '夸张的场面', '漏洞百出的设定', '充满意淫的情怀', '本有的一些场面上的精彩在强大的堆积而成的bug里显得那么微弱', '不能说因为动作场面上花钱了', '文戏给我随便搭个棚子就交差了吧', '吴京努力了', '但是你劲使大了', '3星', '6分', '1', '设定有点像好莱坞动作片那一套', '男主的女人总立flag', '不是消失就是疑似扑街', '2', '太极宗师后', '半红不紫多年', '吴京很厉害', '靠战狼系列走出条自己的动作片路线', '金链大哥片', '糙汉の最爱', '3', '能看出007', '碟中谍', '史泰龙', '斯坦森影子在', '4', '好莱坞团队对爆米花片总体质量提升', '战狼2比第1部更紧凑了', '7分', '坦克挡坦克', '王牌斗王牌', '电影里最热血的场景是', '一个人面对成群坦克毫无惧色', '要手无寸铁的话', '才是真的英雄', '赵东来', '达康书记', '我们接到在非洲卧底的冷锋报告', '丁义珍现在非洲', '我们请求抓捕', '李达康', '东来', '这件事先不要声张', '特别是别让省厅知道', '就你和我一起去非洲', '加上冷锋同志', '三人逮捕丁义珍', '这次行就叫战狼2吧', '如果把爱国和评价主旋律电影捆绑在一起', '那对电影本身的尊重何在', '夸张的人设', '夸张的场面', '漏洞百出的设定', '充满意淫的情怀', '本有的一些场面上的精彩在强大的堆积而成的bug里显得那么微弱', '不能说因为动作场面上花钱了', '文戏给我随便搭个棚子就交差了吧', '吴京努力了', '但是你劲使大了', '3星', '6分', '1', '设定有点像好莱坞动作片那一套', '男主的女人总立flag', '不是消失就是疑似扑街', '2', '太极宗师后', '半红不紫多年', '吴京很厉害', '靠战狼系列走出条自己的动作片路线', '金链大哥片', '糙汉の最爱', '3', '能看出007', '碟中谍', '史泰龙', '斯坦森影子在', '4', '好莱坞团队对爆米花片总体质量提升', '战狼2比第1部更紧凑了', '7分', '坦克挡坦克', '王牌斗王牌', '电影里最热血的场景是', '一个人面对成群坦克毫无惧色', '要手无寸铁的话', '才是真的英雄', '现在还有单排上分的人啊', '一部判断是否双标的电影', '美国主旋律还有的套路', '它都有', '美国主旋律还有的特长', '它在努力学', '还有一些距离', '但以主流商业片惯常使用且不得不使用的方法来指责其短板', '就是双标价值观和审美水准的问题了', '美国人都把汽车当飞机开了', '中国人拍个坦克漂移怎么了', '是轧了你家按揭商品房了', '一部让7亿直男看后就高潮的电影', '竟然有那么多水军', '牛逼了', '无论影片是否意在宣扬什么主旋律', '我终究还是看到了强国强民的影子', '国强', '民强', '才是真实的', '其余都是骗人的', '尴尬癌患者不适合的片子非你莫属', '大概在豆瓣给国产打差评是政治正确吧', '别几把臭不要脸', '预告片就尴尬满满', '谁他妈骂我', '谁不孕不育', '子孙满堂', '给自己刷到7', '5', '真的已经是自我认识偏差到精神分裂的境界了', '赶紧去看看病吧', '为了营造清朗的网络环境', '所有水军的阴部都糜烂了', '中国能拍出这样的电影已经很不错了', '至少过程是很给力的', '是不是跪的久了', '别人扶你站起来你都站不起来', '好看', '虽然吴京的主角光环有点重', '但是最后一屏真是升起了爱国心', '故事非常紧凑', '一直在打', '男主几乎一直满血', '和战狼1反差太大', '战狼1一大队人马抓一小帮雇佣兵', '这次和达康书记两人完虐一支部队', '国旗光环简直太闪亮', '真是国威浩荡', '义愤填膺处更是想砸场子', '最后凯旋有点像美队1里救众人凯旋', '还有那一振臂', '让人太激动了', '有些瑕疵', '但瑕不掩瑜', '我想说太棒了', '本来是一星的', '因为编剧老师和我在微博上是互关的好友关系', '加之', '实际上看来', '本片硬伤虽多', '情感车祸现场也多', '但仍然不失为一部进步之作', '所以多加了一星', '这部片面向的共鸣观众', '约为三线城市以后', '大三以下或同等学力男生', '理性地说', '这是一块尚未完全开发的投资洼地', '诸位成年人可稍加留意', 'にまび', '好莱坞很多大片都是把美国人拍的无所不能', '也没见很多人骂啊', '这个电影把中国人拍的这么强大', '为什么这么多人骂', '况且这个电影有一定的历史基础', '总会找到一个上帝', '端坐天堂', '就算一个男人面临再窘迫的环境', '他至少还可以拥有自尊', '梦想以及明天', '我也要守护好自己的理想', '关于电影而言有些副线做的稍显简单', '故事还有一定的潜力可以挖掘', '终于把这部豆瓣50万人看过的高分神作看了', '囧', '爱与坚持', 'really励志', '很多时候', '再艰难也要撑下去', '因为更艰难的日子在未来', '想起来徐本禹说的那句话', '你穷', '别人会同情你', '但你一直穷', '别人不会一直同情你的', '幸福来敲门', '虽然算不上是完美的励志片', '但它至少教会我一点', '不要把自己经历过的事儿当个事儿', '即使能感动他人', '这些也什么都不是', '把这些扔在脑后', '让生命爆发出战斗力', '去击败一切', '才是真正动人的感人故事', '看到男主最困难的时候去捐血换吃食', '带着西装上班', '特别心酸', '而这份难受的对比使得美好结局更激动人心', '感人肺腑', '让我印象深刻的画面是父子在卫生间过夜', '父亲的鞋少了一只', '借给老板五块钱', '全片基本上都在讲男主角是怎么受难的', '幸福只有结尾有一点', '就算身在阶级底层', '父亲也极力让儿子相信世界并不是那么残酷无情', '故事非常感人', '剧本牛', '导演功力非常深厚', '演员演技在线倾力出演', '非常棒', '大学英语课看的电影', '非常典型的好莱坞励志片', '也很适合学习英语', 'You', 'got', 'a', 'dream', 'you', 'gotta', 'protect', 'it', 'Don', 't', 'let', 'your', 'dreams', 'be', 'dreams', '经典能成为经典', '是有卓越之处', '看这部电影', '心中蒙着一层暖意', '篮球场上父子的对话很戳人心', '父亲之所以这么拼命', '是出于对自己的信心', '也是出于对孩子对家庭的责任感吧', '看了这部电影', '突然就有了勇气去闯去拼搏', '好的电影亮点肯定不止一个', '这部电影赢得我青睐', '赚得我泪点的地方在于父子情', '拼搏气', '生活总有这样那样说得出说不出的苦', '也许比想象中还要糟一点', '但只有咬牙坚持下去', '每天给自己一个微笑然后继续努力', '总有一天幸福会不期而遇', '我们都不晓得幸福什么时候会来敲门']\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 切词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(s): return list(jieba.cut(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutText(text):\n",
    "    TOKEN = []\n",
    "    for line in text:\n",
    "        #print(line)\n",
    "        TOKEN += cut(line)\n",
    "    return TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 2.848 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "TOKEN = cutText(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add,mul\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsCount = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wordsCount.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一元语言模型\n",
    "def unigramModel(word):\n",
    "    return wordsCount[word]/len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "wordsCount2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二元语言模型\n",
    "def bigramModel(word1,word2):\n",
    "    if word1+word2 in TOKEN_2_GRAM: \n",
    "        return wordsCount2[word1+word2]/wordsCount[word1]\n",
    "    else:\n",
    "        return 1/len(TOKEN_2_GRAM)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSenProb(sentence):\n",
    "    words = cut(sentence)\n",
    "    senProb = 1\n",
    "    for i,word in enumerate(words[:-1]):\n",
    "        secondWord = words[i+1]\n",
    "        prob = bigramModel(word,secondWord)\n",
    "        senProb *= prob\n",
    "    return senProb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 判断合理性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我们讨厌讨厌篮球足球斗殴游泳读书篮球打架\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3141807603455278e-56"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = createSentence(createGramma(hobby),'hobby')\n",
    "print(s)\n",
    "getSenProb(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57是9。8是73。-->由于原因72。-->解决办法57。解决办法972443。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.113752923420435e-151"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = createSentence(createGramma(paper),'paper')\n",
    "print(s)\n",
    "getSenProb(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(strings): \n",
    "    bestSen ={}\n",
    "    for s in strings:\n",
    "        reStr = re.findall('\\w+',s)\n",
    "        #print(reStr)\n",
    "        targetStr = ''.join(reStr)\n",
    "        #print(len(targetStr),targetStr)\n",
    "        strProb = getSenProb(targetStr)\n",
    "        bestSen[s]=strProb  \n",
    "    bestSentence = max(bestSen,key = bestSen.get)\n",
    "    #print(bestSen[bestSentence])\n",
    "    print(\"{} with prob {} is the best tentences among\".format(bestSentence,bestSen[bestSentence]))\n",
    "    for k in bestSen:\n",
    "        print('\\t{} with prob {}'.format(k,bestSen[k]))     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对paper进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题8？问题88？-->分析993。-->解决方法3。 with prob 1.2020620023387552e-45 is the best tentences among\n",
      "\t4是47。3是7。-->因为原因44。因为原因88。由于原因47。-->解决办法6。解决办法28。 with prob 3.010511004919631e-107\n",
      "\t46是7。-->因为原因9。由于原因28949。-->解决办法4。 with prob 7.95009539107044e-65\n",
      "\t问题8？问题88？-->分析993。-->解决方法3。 with prob 1.2020620023387552e-45\n",
      "\t2是297。727是37。-->由于原因358。-->解决办法46。 with prob 4.593276301209677e-54\n",
      "\t假设2存在。假设1589存在。-->实验9。证据3。-->证明假设8是确的。证明假设5是确的。证明假设5是确的。 with prob 1.235808655706861e-164\n",
      "\t问题3？-->分析8。-->解决方法3132。解决方法3。解决方法7。 with prob 1.8535106205110965e-61\n",
      "\t问题8？-->分析2。分析7。分析5。分析2。分析31。-->解决方法8。解决方法71。解决方法9。 with prob 1.9584217892437145e-115\n",
      "\t假设8存在。假设3存在。-->实验11864。实验6。实验32。证据8。-->证明假设3是错的。 with prob 1.5195253131406572e-114\n",
      "\t31是1。-->因为原因16。因为原因7。因为原因8。由于原因65。-->解决办法2。 with prob 9.142572443915508e-97\n",
      "\t288是477。2是76325。6是1。-->由于原因3。由于原因55。-->解决办法4751。解决办法4。 with prob 9.293137235264358e-97\n",
      "\t假设7存在。-->实验513。证据28。实验1。实验5。-->证明假设5是对的。 with prob 7.775296664676301e-94\n",
      "\t假设4存在。-->证据1。-->证明假设5是错误的。 with prob 5.58935717854932e-55\n",
      "\t197是198957。35133是56。-->由于原因7。因为原因2。-->解决办法1。解决办法94。 with prob 3.6546257870952294e-92\n",
      "\t问题9？问题3？-->分析935。-->解决方法5723。解决方法5。解决方法664。 with prob 8.88618536476086e-75\n",
      "\t问题8？-->分析937。分析6。-->解决方法5。解决方法452。 with prob 1.4616255178887497e-60\n",
      "\t3是751。-->由于原因73。因为原因4。-->解决办法2。解决办法8。 with prob 4.6003709039764126e-73\n",
      "\t假设5存在。-->实验63886。证据5。-->证明假设1是对的。证明假设9是错的。 with prob 2.0816274116836657e-95\n",
      "\t6是452216。49是1192。328是84876938。7是57。4是65。-->因为原因99。-->解决办法88。 with prob 9.31455280238752e-97\n",
      "\t问题5？-->分析5。分析57。分析4。-->解决方法6。解决方法5148。 with prob 3.567298966489841e-77\n",
      "\t问题79944？-->分析4。-->解决方法73847693。解决方法2。解决方法36493。 with prob 1.8871576263887324e-65\n"
     ]
    }
   ],
   "source": [
    "strings = generate_n(paper,'paper',20)\n",
    "generate_best(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对hobby进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你喜欢游泳打架斗殴 with prob 1.4432085018480188e-13 is the best tentences among\n",
      "\t你们讨厌讨厌篮球读书打架 with prob 3.1844946877101213e-25\n",
      "\t我你我们你们喜欢打架 with prob 5.771013165972311e-23\n",
      "\t你他们我们你们他小明喜欢喜欢斗殴 with prob 8.745965587824757e-38\n",
      "\t我们你喜欢讨厌打架篮球游泳游泳 with prob 4.0945651786731385e-35\n",
      "\t你我讨厌篮球游泳 with prob 8.317916649547283e-19\n",
      "\t小明讨厌打架游泳 with prob 1.0497368288567644e-20\n",
      "\t他们他小明喜欢喜欢游泳 with prob 1.4077664711132484e-20\n",
      "\t他们讨厌讨厌篮球足球 with prob 2.6112856439222993e-23\n",
      "\t他讨厌足球 with prob 4.794245722913927e-14\n",
      "\t他们你们喜欢喜欢讨厌游泳 with prob 3.1179766802065304e-23\n",
      "\t我们喜欢读书游泳 with prob 2.1986218759515458e-14\n",
      "\t他我们我们喜欢篮球篮球斗殴游泳篮球游泳 with prob 2.429058041151822e-42\n",
      "\t我们喜欢讨厌喜欢讨厌游泳打架斗殴 with prob 3.109131634860466e-31\n",
      "\t小明喜欢足球打架斗殴 with prob 3.535318724956808e-18\n",
      "\t你喜欢游泳打架斗殴 with prob 1.4432085018480188e-13\n",
      "\t小明讨厌喜欢讨厌篮球打架打架 with prob 1.436371752225567e-33\n",
      "\t你们小明讨厌斗殴 with prob 1.0497368288567644e-20\n",
      "\t小明讨厌足球 with prob 4.794245722913927e-14\n",
      "\t我们我们讨厌讨厌喜欢讨厌喜欢斗殴 with prob 1.4353074352714465e-36\n",
      "\t小明你喜欢讨厌斗殴游泳 with prob 6.91909618725788e-27\n"
     ]
    }
   ],
   "source": [
    "strings = generate_n(hobby,'hobby',20)\n",
    "generate_best(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "明天晚上请你吃大餐，我们一起吃苹果\n",
      "---- 1.3464702195831717e-37 : 今天晚上请你吃大餐，我们一起吃日料\n",
      "---- 6.463057053999224e-37 : 明天晚上请你吃大餐，我们一起吃苹果\n",
      "真是一只好看的小猫\n",
      "---- 3.089486767055563e-22 : 真事一只好看的小猫\n",
      "---- 9.575848998641689e-17 : 真是一只好看的小猫\n",
      "今晚我去吃火锅\n",
      "---- 1.7448532592156326e-08 : 今晚我去吃火锅\n",
      "---- 5.14617845838306e-19 : 今晚火锅去吃我\n",
      "养乐多绿来一杯\n",
      "---- 9.40970701258867e-18 : 洋葱奶昔来一杯\n",
      "---- 4.794245722913927e-14 : 养乐多绿来一杯\n"
     ]
    }
   ],
   "source": [
    "need_compared = [\n",
    "    \"今天晚上请你吃大餐，我们一起吃日料 明天晚上请你吃大餐，我们一起吃苹果\",\n",
    "    \"真事一只好看的小猫 真是一只好看的小猫\",\n",
    "    \"今晚我去吃火锅 今晚火锅去吃我\",\n",
    "    \"洋葱奶昔来一杯 养乐多绿来一杯\"\n",
    "]\n",
    "for s in need_compared:\n",
    "    s1,s2 = s.split()\n",
    "    p1,p2 = getSenProb(s1),getSenProb(s2)\n",
    "    s = s1 if p1>p2 else s2\n",
    "    print(s) \n",
    "    print('-'*4,p1,':',s1)\n",
    "    print('-'*4,p2,':',s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "    当句子的长度不同时，该模型更倾向于相对较短的句子。\n",
    "    为提升模型预测的准确度，一方面增加模型训练的数据长度；另一方面还可以改进模型，对于句子的每个分词，可以考虑增加一个权重参数，以抵消应长度较长导致的准确率越低的现象；还可以把较长的句子分成多个短句，然后对多个短句的概率进行加权求和，将其结果与短句进行比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
